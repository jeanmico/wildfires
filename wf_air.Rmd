---
title: "Wildfires"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Libraries
```{r}
library(tmap)
library(ggplot2)
library(tidyr)
library(ggmap)
library(rgdal)
library(rgeos)
library(maptools)
library(dplyr)
library(tmap)
library(gstat)
library(raster)
library(sp)
library(sf)
```

Constants and globals
```{r}

# file naming conventions
fname_img <<- paste('/Users/student/wildfires/images/', Sys.Date(), '_', sep = '')
fname_csv <<- paste('/Users/student/wildfires/output/', Sys.Date(), '_', sep = '')

# define a bounding box for displaying maps
bound_box <<-  as(raster::extent( -122.7, -121.55, 37, 38.2), "SpatialPolygons")
proj4string(bound_box) <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
```

Functions
```{r}
file_naming <- function(f_name, f_type) {
  if (f_type == 'image') {
    return(paste(fname_img, f_name, '.png', sep=''))
  }
  else if (f_type == 'csv') {
    return(paste(fname_csv, f_name, '.csv', sep = ''))
  }
}

```

```{r}
idw_interpolate <- function(data_sp, interp_col, grid_n, weight_power) {
  # create empty grid
  grd <- as.data.frame(spsample(data_sp, 'regular', n=grid_n))
  names(grd) <- c("longitude", "latitude")
  coordinates(grd) <- c('longitude', 'latitude')
  gridded(grd) <- TRUE
  fullgrid(grd) <- TRUE
  
  # add projection to empty grid
  #proj4string(data_sp)
  crs(grd) <- proj4string(data_sp)
  
  # interpolate!
  data_sp_idw <- gstat::idw(data_sp[[interp_col]] ~ 1, data_sp, newdata=grd, idp=weight_power)
  
  #file_name = file_naming(fname, 'image')
  
  return(data_sp_idw)
}
```

```{r}
sensor_map <- function(sensor_df) {
  sensors_pa <- st_as_sf(sensor_df, coords =c("lon", "lat"), crs=4326)
  sens_plt <- tm_shape(sensors_pa) +
    tm_dots(col='gray')
  
  file_name = file_naming(fname, 'image')
  tmap_save()
  
  return(sens_plt)
}
```

```{r}
raster_map <- function(raster_sp, points_sp, bounding_box, legend_show, rast_title, fname) {
  r <- raster(raster_sp)
  
  # clip to California
  r_clip <- mask(r, ca_county_map)
  
  # map the interpolated raster
  rast_plt <- tm_shape(r_clip, bbox = bound_box) +
    tm_raster(n=12, palette = "YlOrRd", title=rast_title, style='fixed', breaks=c(0,25,50,75,100,125,150,175,200,225,250,300,400)) +
    tm_shape(points_sp) + tm_dots(size=.2) +
    tm_legend(legend.outside=TRUE, legend.show=legend_show, legend.text.size=1.2)
  
  file_name = file_naming(fname, 'image')
  tmap_save(rast_plt + tm_layout(outer.margins = c(0,0,0,0)), file=file_name)
  
  return(rast_plt)
}
```

```{r}
line_plot <- function(df, xcol, ycol, line_title, x_label, y_label, fname) {
  Line_plt <- ggplot(df, aes(x=datesort, y=daily_mean_pm25, color = as.character(site_id), label=county)) +
    geom_line() +
    scale_color_brewer(palette="Accent") +
    xlab(x_label) +
    ylab(y_label) +
    labs(color = "Sensor", labels = plot_df$county) +
    scale_fill_discrete(breaks=plot_df$county)
  
  file_name = file_naming(fname, 'image')
  ggplot.save()
  
  return(line_plt)
}

```

# Start of code

Get a California county map
```{r}
# USA county map
county_map = rgdal::readOGR('/Users/student/wildfires/cb_2018_us_county_5m')

# Restrict to California
ca_county_map <- subset(county_map, STATEFP == '06')
ca_county_map <<- spTransform(ca_county_map, CRS="+proj=longlat +datum=WGS84")
```


# PurpleAir data
```{r}
pa_pm25 = read.csv('~/wildfires/2018_purpleair.csv')

# remove NA (do a better job of trying to fix NA)
pa_pm25 <- pa_pm25 %>% filter(!is.na(pm25_atm_corr))

sensors_pa <- st_as_sf(pa_pm25, coords =c("lon", "lat"), crs=4326)

tm_shape(sensors_pa) +
  tm_dots(col='gray')
```







Read in the PM2.5 EPA data for 2018 (all of California)
```{r EPA data read}
ca_pm25 = read.csv('~/wildfires/2018_CA_PM25_EPA.csv')

# Rename columns for convenience
colnames(ca_pm25) = c('date', 'source', 'site_id', 'poc', 'daily_mean_pm25', 'units', 'daily_aqi_value', 'site_name', 'daily_obs_count', 'percent_complete', 'aqs_parameter_code', 'aqs_parameter_desc', 'cbsa_code', 'cbsa_name', 'state_code', 'state', 'county_code', 'county', 'latitude', 'longitude')

# Sort by date
ca_pm25 <- ca_pm25 %>% mutate(datesort = as.Date(date, format='%m/%d/%Y'))

# filter out the counties we don't want
exclude_counties = read.csv('~/wildfires/exclude_county_sensors.csv')

ca_pm25 <- ca_pm25 %>% filter(!(county_code %in% exclude_counties$code))

epa_ids = unique(ca_pm25$site_id)
```

# Geographic analysis

Get a dataframe of just the sensors with latitude and longitude
```{r}
# this serves as a reference file for the EPA sensors
sensors_epa = ca_pm25 %>% distinct(site_id, .keep_all=TRUE) %>% dplyr::select(site_id, site_name, cbsa_code, cbsa_name, state_code, state, county_code, county, latitude, longitude)
```

construct a 'shapefile' out of the csv
```{r}
sensors_sf <- st_as_sf(ca_pm25, coords =c("longitude", "latitude"), crs=4326)
```

Display the sensors on a map
```{r}
tm_shape(sensors_sf) +
  tm_dots(col='gray')
```

Testing out interpolation for a single day's readings

Read in the watershed data to interpolate by watershed.
```{r}
watershed = rgdal::readOGR('/Users/student/wildfires/watershed_8')
watershed_map <<- spTransform(watershed, CRS="+proj=longlat +datum=WGS84")
watershed_map
ca_county_map

water_clip <- crop(watershed_map, ca_county_map) # crop instead of mask here bc the object is not a raster

# map the interpolated raster
water_plt <- tm_shape(water_clip, bbox = pa_sp) + tm_polygons(col = '#F3DFA2') +
  tm_shape(pa_sp) +
  tm_dots(col='#6E2594', size = .15) + 
  tm_shape(sensors_sf) + tm_dots(col = '#BB4430', size = .15) +
  tm_layout(bg.color = '#7EBDC2')

water_plt

file_name = file_naming('watershed_sensors', 'image')
tmap_save(water_plt + tm_layout(outer.margins = c(0,0,0,0)), file=file_name)
```

Combine EPA and PurpleAir sensors into one dataframe, assign each a watershed #

```{r}
# first, make a giant dataframe with all sensors (EPA and Purple) for all days

# get the purplair data
purpleair_fulldf <- data.frame(matrix(ncol = 8, nrow = 0))
colnames(purpleair_fulldf) = c("sensor_id", "day_date", "mean_pm25_atm", "mean_pm25_1", "mean_temp", "mean_humid", "pm25_atm_corr", "pm25_1_corr"  )

fpath = '/Volumes/Padlock/purpleair_2018_corr/'

fnames <- list.files(fpath, full.names = TRUE)

for (i in 1:length(fnames)) {
  tmp <- read.csv(fnames[i])
  purpleair_fulldf <- rbind(purpleair_fulldf, tmp)
}

# combine master PurpleAir and EPA
colnames(sensors_epa)

#add a check to see whether these files have been created before doing this
sensors_epa <- ca_pm25 %>% dplyr::select(site_id, date,  daily_mean_pm25, latitude, longitude, county_code)
sensors_epa <- sensors_epa %>% mutate(source = 'epa')

pdict <- read.csv('~/GitHub/wildfires/purpleair_sensors.csv')
sensors_purple <- merge(purpleair_fulldf, pdict, by.x = 'sensor_id', by.y = 'id', all.y = FALSE)
sensors_purple <- sensors_purple %>% dplyr::select(sensor_id, day_date, pm25_1_corr, lat, lon)

# get lat and long from purple air
colnames(sensors_purple) <- c('site_id', 'date',  'daily_mean_pm25', 'latitude', 'longitude')
sensors_purple <- sensors_purple   %>% mutate(county_code = 0, source = 'purple')



sensors_full = rbind(sensors_epa, sensors_purple)

coordinates(sensors_full) <- ~longitude+latitude
crs(sensors_full) <- CRS( "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")  # WGS84

sensors_water <- sensors_full
crs(sensors_water) <- proj4string(CRS( "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))

#proj4string(day_sp)
#crs(grd) <- proj4string(day_sp)
crs(watershed) <- CRS( "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")

sensors_water_wgs <- over(sensors_full, watershed[, "OBJECTID"])
#sensors_water_nad <- over(sensors_water, watershed[, "OBJECTID"])

# assign a watershed

sensors_full$watershed_w = sensors_water_wgs$OBJECTID

sensors_full$watershed_n = sensors_water_nad$OBJECTID


table(sensors_full$watershed_w)

table(sensors_full$watershed_n) == table(sensors_full$watershed_w)

#what ids are we missing ugh <- still need to deal with this

dids = unique(sensors_purple$site_id)

rids = unique(pdict$id)

a = setdiff(dids, rids)


```

Merge some of your watersheds
```{r merge watersheds}


```

Write a kriging method (once complete, make it a function above and delete this chunk)

```{r kriging variogram}
# this chunk should be turned into a function above and then deleted

# define the 1st order polynomial equation
kv <- as.formula(daily_mean_pm25 ~ latitude + longitude)

# filter to a single date
sensors_tmpday <- subset(sensors_full, as.Date(date, '%m/%d/%Y') == as.Date('2018-11-15'))

# compute the sample variogram
var_krig <- variogram(kv, sensors_tmpday)

# make a plot to assess the fit
var_fit <- fit.variogram(var_krig, fit.ranges = FALSE, fit.sills = FALSE, 
                         vgm(psill=14, model="Sph", range=590000, nugget=0))

plot(var_krig, var_fit)

```

```{r kriging}
# this chunk should be turned into a function above and then deleted

# define the trend model

# perform the krige interpolation


# convert kriged surface to raster object for clipping

# plot the raster map

```

```{r kriging variance and confidence maps}
# this chunk should be turned into a function above and then deleted



```

For each day for each watershed, interpolate
```{r}
library(lubridate)

startdate = as.Date('2018-11-01')
enddate = as.Date('2018-11-30')

datelist = seq(startdate, enddate, by='days')

rast_basename = '/Volumes/Padlock/wildfires/rasts/'




for (i in 1:length(datelist)) {
  tmpsensors = subset(sensors_full, as.Date(date, '%m/%d/%Y') == datelist[i])
  tmprast = idw_interpolate(tmpsensors , 'daily_mean_pm25', 500000, 3)
  
  print(i)
  print(range(tmpsensors$daily_mean_pm25))
  
  raster_map(tmprast, pa_sp, pa_sp, TRUE, datelist[i], i)
  
  #rastname = paste(rast_basename, i, '.grd', sep = '_')
  #writeRaster(raster(tmprast), filename = rastname)
}
#idw_interpolate <- function(data_sp, interp_col, grid_n, weight_power) {
qtst <- idw_interpolate(tmpsensors , 'daily_mean_pm25', 500000, 3)

```
```{r}
rast_basename = '/Volumes/Padlock/wildfires/rast_watershed/'
watersheds = unique(sensors_full$watershed_n)


for (i in 1:length(datelist)) {
  for (j in 1:length(watersheds)) {
    tmpsensors = subset(sensors_full, as.Date(date, '%m/%d/%Y') == datelist[i])
    tmpsensors = subset(tmpsensors, watershed_n == watersheds[j])
    tmprast = idw_interpolate(tmpsensors , 'daily_mean_pm25', 500000, 3)
    
    print(i)
    print(range(tmpsensors$daily_mean_pm25))
    
    
    
    rastname = paste(rast_basename, i, watersheds[j], '.grd', sep = '_')
    writeRaster(raster(tmprast), filename = rastname)
  }
}
#idw_interpolate <- function(data_sp, interp_col, grid_n, weight_power) {
qtst <- idw_interpolate(tmpsensors , 'daily_mean_pm25', 500000, 3)
```



```{r}

r <- raster(qtst)

# clip to California
r_clip <- mask(r, ca_county_map)

# map the interpolated raster
rast_plt <- tm_shape(r_clip, bbox = bound_box) +
  tm_raster(n=12, palette = "YlOrRd", title='', style='fixed', breaks=c(0,25,50,75,100,125,150,175,200,225,250,300,400)) 
  #tm_shape(points_sp) + tm_dots(size=.2) +
  #tm_legend(legend.outside=TRUE, legend.show=legend_show, legend.text.size=1.2)

rast_plt


test_rast <- raster_map(qtst, pa_sp, pa_sp, TRUE, 'test, corrected', 'test_idw')

test_rast

```


```{r}
county_plt <- tm_shape(ca_county_map) + tm_polygons()

county_plt


file_name = file_naming('not_eldritch_ca', 'image')
tmap_save(county_plt + tm_layout(outer.margins = c(0,0,0,0)), file=file_name)
```




```{r}
r <- raster(day_sp.idw)

# clip to California
r_clip <- mask(r, ca_county_map)

# map the interpolated raster
epaplt_full <- tm_shape(r_clip) +
  tm_raster(n=10, palette = "YlOrRd", title="") +
  tm_shape(day_sp) + tm_dots(size=.2) +
  tm_legend(legend.outside=TRUE, legend.text.size=1.2)

epaplt_full

tmap_save(epaplt_full, file='/Users/student/wildfires/20181115_epa_full.png',  outer.margins = c(0,0,0,0))
```

```{r}
epaplt <- tm_shape(r_clip, bbox = bound_box) +
  tm_raster(n=10, palette = "YlOrRd", title="") +
  tm_shape(day_sp) + tm_dots(size=.2) +
  tm_legend(legend.outside=TRUE, legend.text.size=1.2)

epaplt

tmap_save(epaplt + tm_layout(outer.margins = c(0,0,0,0)), file='/Users/student/wildfires/20181115_epa.png',  outer.margins = c(0,0,0,0))

```





Evaluating the interpolation

RMSE - leave one out validation
```{r}
IDW.out <- vector(length = length(pa_sp))

# create a vector of models leaving one point out
for (i in 1:length(P)) {
  IDW.out[i] <- idw(mean_pm25_atm ~ 1, pa_sp[-i,], pa_sp[i,], idp=2.0)$var1.pred
}

# plot the predicted against the observed
pred_obs_plt <- ggplot(aes(x = mean_pm25_atm, y = IDW.out), data = )
```

Map out the locations of our hourly data sensors...are we missing any areas?

Try other ways of interpolating data

# Kriging

# Polynomial







